<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  

  
  <title>最近邻搜索NN——综述 | holdfire</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. 简介   最近邻搜索的数学描述为：给定d维欧式空间ℜD\Re^DℜD中的一个查询向量qqq，从包含N个向量的数据库XXX中找到一个向量NNqNN_qNNq​,NNqNN_qNNq​和qqq的距离最小。 NN(q)=arg min⁡x∈Xdist(q,x)NN(q) = arg \ \min_{x \in X} dist(q,x)  NN(q)=arg x∈Xmin​dist(q,x) 通过">
<meta name="keywords" content="图像检索,最近邻搜索">
<meta property="og:type" content="article">
<meta property="og:title" content="最近邻搜索NN——综述">
<meta property="og:url" content="http:&#x2F;&#x2F;holdfire.github.io&#x2F;2019&#x2F;11&#x2F;05&#x2F;computer-vision-nn&#x2F;index.html">
<meta property="og:site_name" content="holdfire">
<meta property="og:description" content="1. 简介   最近邻搜索的数学描述为：给定d维欧式空间ℜD\Re^DℜD中的一个查询向量qqq，从包含N个向量的数据库XXX中找到一个向量NNqNN_qNNq​,NNqNN_qNNq​和qqq的距离最小。 NN(q)=arg min⁡x∈Xdist(q,x)NN(q) = arg \ \min_{x \in X} dist(q,x)  NN(q)=arg x∈Xmin​dist(q,x) 通过">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-11-05T11:15:30.154Z">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="holdfire" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">holdfire</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">学无止境，不忘初心！</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://holdfire.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-computer-vision-nn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/05/computer-vision-nn/" class="article-date">
  <time datetime="2019-11-05T07:39:19.000Z" itemprop="datePublished">2019-11-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      最近邻搜索NN——综述
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4>
<p>  最近邻搜索的数学描述为：给定d维欧式空间<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">ℜ</mi><mi>D</mi></msup></mrow><annotation encoding="application/x-tex">\Re^D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">ℜ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span></span></span></span></span></span></span></span>中的一个查询向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>，从包含N个向量的数据库<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>中找到一个向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">NN_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><msub><mi>N</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">NN_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>的距离最小。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mi>N</mi><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mtext> </mtext><munder><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">NN(q) = arg \ \min_{x \in X} dist(q,x) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.521701em;vertical-align:-0.771701em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace"> </span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.055669em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.771701em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span></p>
<p>通过线性查找，计算查询向量和数据库中各个向量的距离。但如果是海量的高维数据集，采用线性查找会非常耗时。<br />
  为了解决这个问题，我们需要采用一些类似索引的技术来加速查找的过程，这类方法包括：最近邻检索(Nearest Neighbor Search, NN)和近似最近邻检索(Approximate Nearest Neighbor Search, ANN)。主要有以下两种思路：一种是基于提升检索结构性能的方法，大多基于树形结构。另一种是基于对数据本身的处理，包括哈希算法，向量量化等方法。<br />
  近似最近邻搜索方法ANN通过对数据分析聚类的方法，对数据库中的数据进行分类或编码。对于目标数据，根据其数据特诊预测其所属的数据类别，返回类别中的部分或全部作为检索结果。主要有两类方案，第一类是缩短距离计算时间，例如将维度d由1000将到100，这类方法主要包括哈希散列和矢量量化。第二类方法是通过减少距离的计算次数来实现的。例如将计算次数由1,000,000次减少到1,000次。本文暂不关注。</p>
<h4 id="11-基于提升检索结构性能的方法"><a class="markdownIt-Anchor" href="#11-基于提升检索结构性能的方法"></a> 1.1 基于提升检索结构性能的方法</h4>
<ul>
<li>随机k-d树算法：对数据的处理，减少距离计算的次数</li>
<li>优先搜索k-means树算法</li>
<li>层次聚类树算法</li>
</ul>
<h4 id="12-对数据的处理缩短距离计算的时间哈希散列"><a class="markdownIt-Anchor" href="#12-对数据的处理缩短距离计算的时间哈希散列"></a> 1.2 对数据的处理，缩短距离计算的时间——&gt;哈希散列</h4>
<p>  哈希散列是通过哈希函数把向量q变化为二值码，然后用Hamming距离来近似表示原来两个向量的距离。<br />
  核心思想是：在高维空间相邻的数据，经过哈希函数的映射投影转化到低维空间后，它们落入同一个吊桶的概率很大，而不相邻的数据映射到同一个吊桶的概率很小。在检索时将欧式空间的距离计算转化到汉明（Hamming）空间，并将全局检索转化为对映射到同一个吊桶中的数据进行检索，从而提高了检索速度。这种方法的主要难点在于如何寻找适合的哈希函数。</p>
<h4 id="13-对数据的处理缩短距离计算的时间向量量化"><a class="markdownIt-Anchor" href="#13-对数据的处理缩短距离计算的时间向量量化"></a> 1.3 对数据的处理，缩短距离计算的时间——&gt;向量量化</h4>
<p>  向量量化是通过聚类把向量集聚成若干类，每类里面的向量用对应的类中心来近似。这样子，每个向量只需要用其对应的聚类中心的索引ID来表示，其与查询向量间的距离用其对应的聚类中心与查询向量间的距离来近似。向量量化带来了两项优势：向量需要的存储空间变少了，只需保存对应的聚类中心的ID；计算时间减少了，只需要通过聚类中心的索引ID来查询预先计算好的聚类中心与查询向量的距离表格。<br />
  </p>
<h4 id="2-基于提升检索结构性能的方法"><a class="markdownIt-Anchor" href="#2-基于提升检索结构性能的方法"></a> 2. 基于提升检索结构性能的方法</h4>
<p>  1977年，Friedman et al.提出了k-d树，这种结构后来被用于加速精确查找。</p>
<ul>
<li>
<p>random multiple k-d trees和priority search<br />
  相比较普通k-d树，提升了搜索的准确率和搜索效率。相关文章：<a href="">Silpa-Anan &amp; Hartley. Optimised kd-trees for fast image descriptor matching. In CVPR, 2008.</a></p>
</li>
<li>
<p>FLANN方法<br />
   该方法在random k-d trees和hierarchial k-means trees之间进行很好地配置 。相关文章：<a href="">Muja &amp; Lowe. Fast approximate nearest neighbors with automatic algorithm configuration. In VISS-APP(1),.pp.331-340,2009.</a></p>
</li>
<li>
<p>over tree结构<br />
  相关文章：<a href="">Beygelzimer et al., Cover trees for nearest neighbor. In ICML, pp.97-104,2006.</a></p>
</li>
<li>
<p>trinary tree结构<br />
  相关文章:<a href="">Jia et al., 2010. Optimised kd-trees for scable visual descriptor indexing. In CVPR,PP 3392-3399.</a><br />
<a href="">Wang et al.,2014. Trinary-projection trees for approximate nearest neighbor search. IEEE Trans.Pattern Ananl.Mach.Intell.</a></p>
</li>
<li>
<p>基于近邻图的最近邻搜索算法<br />
  相关文献：<a href="">Arya &amp; Mount, 1993. Approximate nearest neighbor queries in fixed dimension. In SODA.</a><br />
<a href="">Wang &amp; Li, 2012. Query-driven iterated neighborhood graph search for large scale indexing.</a><br />
<a href="">Wang et al., 2013. Fast neighborhood graph search using cartesian concatenation. In ICCV. </a></p>
</li>
</ul>
<h4 id="3-基于哈希散列的方法"><a class="markdownIt-Anchor" href="#3-基于哈希散列的方法"></a> 3. 基于哈希散列的方法</h4>
<p>  这类方法将数据库中的向量转换为更短的编码，从而占用的存储空间更小，距离计算的时间也更短。<br />
<code>局部敏感哈希方法的发展</code></p>
<ul>
<li>
<p>1999年，Gionis提出局部敏感哈希方法LSH<br />
  相关文章：<a href="">Gionis. 1999. Similarity search in high dimensions via hashing.</a></p>
</li>
<li>
<p>LSH的基础上Mahalanobis distance，<br />
  相关文章：<a href="">Jain et al. 2008. Fast image search for learned metrics. In CVPR.</a></p>
</li>
<li>
<p>LSH基础上kernalization，<br />
  相关文章：<a href="">Kulis &amp; Grauman. 2009. Kernalized locality-sensitive hashing for scalable image search. In NIPS.</a></p>
</li>
<li>
<p>comlementary hashing，<br />
  相关文章：<a href="">Xu et al. 2011. Comlementary hashing for approximate nearest neighbor search. In ICCV</a></p>
</li>
</ul>
<p><code>设计哈希函数</code></p>
<ul>
<li>
<p>语义哈希(semantic hashing)<br />
  相关文章：<a href="">Salakhutdinov &amp; Hinton. 2009. Semantic hashing. Int.J.Approx.Reasoning.</a></p>
</li>
<li>
<p>shift kernel hashing，<br />
  相关文章：<a href="">Raginsky &amp; Lazebnik. 2009. Local sensitive binary codes from shift-invariant kernels. In NIPS.</a></p>
</li>
<li>
<p>isotropic hashing，<br />
  相关文章：[<a href="">Kong &amp; Li. 2012.Isotropic hashing. In NIPS.</a></p>
</li>
</ul>
<p><code>设计保相似度的哈希函数</code></p>
<ul>
<li>
<p>谱哈希(Spectral hashing)<br />
  这种方法的出发点是希望Hamming距离大的两个数据点在原空间的相似度要小，其目标函数为最小化Hamming距离和原空间相似度的乘积，最后转化为解特征值或特征函数问题。相关文章：<a href="">Weiss et al. 2008. Spectral hashing. In NIPS.</a></p>
</li>
<li>
<p>二值化重建嵌入(binary reconstructive embedding)<br />
  其目标函数是最小化距离重建误差，即希望Hamming距离和原空间里的欧氏距离尽量接近。相关文章：<a href="">Kulis &amp; Darrells. 2009. Learning to hash with binary reconstructive embeddings. In NIPS.</a></p>
</li>
<li>
<p>基于图的哈希(graph-based hashing)<br />
  锚点图哈希(Anchor Graph Hashing, AGH)。相关文章：<a href="">Liu Wei et al. 2012.Hashing with graphs. In ICML.</a></p>
</li>
<li>
<p>半监督哈希(Semi-Supervised Hashing)<br />
  相关文章：<a href="">Wang Jun et al., 2012. Semi-supervised hashing for large scale search.</a></p>
</li>
</ul>
<p><code>设计保序的目标函数</code></p>
<ul>
<li>
<p>三元组损失函数是一种最简单的保序函数<br />
  设计保序的目标函数，使二值空间的序跟原空间的序尽量一致。将搜索问题看成排序问题，找到距离查询点近的向量。如果一个点q与一个点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">p_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的距离比q到点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的距离小，那么在二值空间里，点q与点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">p_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的Hamming距离比q到点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的Hamming距离小也要。相关文章：<a href="">Mohanmmad Norouzi, Fleet. 2011. Minimal loss hashing for compact binary codes.In ICML.</a></p>
</li>
<li>
<p>更高阶的保序目标函数<br />
  相关文章：<a href="">Wang et al.,2013. Order preserving hashing for approximate nearest neighbor search.In ACM Multimedia.</a></p>
</li>
</ul>
<p><code>迭代量化ITQ</code></p>
<ul>
<li>迭代量化(Iterative Quntization, ITQ)的方法<br />
  其出发点不同于保相似度、保距离或者保序，而是把二值编码当成原向量的近似，利用欧氏距离旋转不变性的性质，建立了最小化二值编码重建旋转原向量误差的目标函数，寻找最优的旋转变换和二值编码。尽管直观看上去重建向量的方法比保相似、保距离或者保序的方法简单，近似得更强，但ITQ实际上效果还是很不错的,原因是保相似、保距离或者保序需要建立二元或多元关系，计算复杂度很大，因而需要各种近似，使得最后的效果不如预期。相关文章：<a href="">Gong &amp; Lazebnik. Iterative quantization: A procrustean approach to learning bianry codes. In CVPR,PP.817-824,2011.</a></li>
</ul>
<h4 id="4-向量量化的方法"><a class="markdownIt-Anchor" href="#4-向量量化的方法"></a> 4. 向量量化的方法</h4>
<ul>
<li>
<p>乘积量化(Productive Quantization, PQ)<br />
  乘积量化是信号处理上用到的一种数据压缩技术。相关文章：<a href="https://www.researchgate.net/publication/47815472_Product_Quantization_for_Nearest_Neighbor_Search" target="_blank" rel="noopener">Hervé Jégou,  Douze M ,  Schmid C . Product Quantization for Nearest Neighbor Search[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 33(1):117-128.</a></p>
</li>
<li>
<p>合成量化(Compositive Quantization,CQ)的方法<br />
  相关文章：<a href="">Zhang Ting, Du Chao, Wang Jingdong.Composite quantization for approximative nearest neighbor search.ICML 2014: 838-846.</a> 以及：<a href="">Wang Jingdong, Zhang Ting. Composition Quantization. IEEE Transactions on Pattern Analysis and Machine Intelligence.2018</a></p>
</li>
<li>
<p>加和量化(Additive Quantization, AQ)<br />
  </p>
</li>
<li></li>
</ul>
<p>  </p>
<h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4>
<ol>
<li>微软研究院AI头条——最近邻搜索综述:<a href="https://blog.csdn.net/Y2c8YpZC15p/article/details/86326313" target="_blank" rel="noopener">https://blog.csdn.net/Y2c8YpZC15p/article/details/86326313</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://holdfire.github.io/2019/11/05/computer-vision-nn/" data-id="ck2lzflce000f94vn4qd3bajz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" rel="tag">图像检索</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2/" rel="tag">最近邻搜索</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/11/05/computer-vision-nn-vector-quantization/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          最近邻搜索NN——向量量化
        
      </div>
    </a>
  
  
    <a href="/2019/11/04/personal-ideas-reading-papers/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">学习方法——如何阅读论文</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E6%9D%82%E8%AE%B0/">个人杂记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/">软件安装</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web%E5%89%8D%E7%AB%AF/" rel="tag">web前端</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%87%B8%E4%BC%98%E5%8C%96/" rel="tag">凸优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">卷积神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">图像处理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" rel="tag">图像检索</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">学习方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2/" rel="tag">最近邻搜索</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">监督学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">目标检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag">计算机视觉</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" rel="tag">论文阅读</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" rel="tag">集成学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">非监督学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 17.14px;">C++</a> <a href="/tags/Linux/" style="font-size: 15.71px;">Linux</a> <a href="/tags/Python/" style="font-size: 11.43px;">Python</a> <a href="/tags/web%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">web前端</a> <a href="/tags/%E5%87%B8%E4%BC%98%E5%8C%96/" style="font-size: 11.43px;">凸优化</a> <a href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">卷积神经网络</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 10px;">图像处理</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" style="font-size: 12.86px;">图像检索</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 10px;">学习方法</a> <a href="/tags/%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2/" style="font-size: 12.86px;">最近邻搜索</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 18.57px;">机器学习</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">深度学习</a> <a href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">监督学习</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 11.43px;">目标检测</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 11.43px;">计算机视觉</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 10px;">论文阅读</a> <a href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" style="font-size: 14.29px;">集成学习</a> <a href="/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 11.43px;">非监督学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/11/05/computer-vision-OCR/">文字识别技术简介</a>
          </li>
        
          <li>
            <a href="/2019/11/05/computer-vision-nn-local-sensitive-hash/">最近邻搜索NN——哈希散列方法</a>
          </li>
        
          <li>
            <a href="/2019/11/05/computer-vision-nn-vector-quantization/">最近邻搜索NN——向量量化</a>
          </li>
        
          <li>
            <a href="/2019/11/05/computer-vision-nn/">最近邻搜索NN——综述</a>
          </li>
        
          <li>
            <a href="/2019/11/04/personal-ideas-reading-papers/">学习方法——如何阅读论文</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 holdfire<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>