<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>holdfire</title>
  
  <subtitle>学无止境，不忘初心！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://holdfire.github.io/"/>
  <updated>2019-11-09T17:51:08.618Z</updated>
  <id>http://holdfire.github.io/</id>
  
  <author>
    <name>holdfire</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CUDA编程——快速入门篇</title>
    <link href="http://holdfire.github.io/2019/11/10/cuda-learning1/"/>
    <id>http://holdfire.github.io/2019/11/10/cuda-learning1/</id>
    <published>2019-11-09T17:01:27.000Z</published>
    <updated>2019-11-09T17:51:08.618Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  CUDA(Computer Unified Device Architecture)的中文全称是计算统一设备架构。</p><h4 id="2-gpu架构的特点"><a class="markdownIt-Anchor" href="#2-gpu架构的特点"></a> 2. GPU架构的特点</h4><h5 id="串行计算和并行计算"><a class="markdownIt-Anchor" href="#串行计算和并行计算"></a> 串行计算和并行计算：</h5><p>  首先，高性能计算的关键是利用多核处理器进行并行计算。一个程序可不可以进行并行计算，关键就在于我们要分析出该程序可以拆分出哪几个执行模块，这些执行模块哪些是独立的，哪些又是强依赖强耦合的，独立的模块我们可以试着设计并行计算，充分利用多核处理器的优势进一步加速我们的计算任务，强耦合模块我们就使用串行编程，利用串行+并行的编程思路完成一次高性能计算。</p><h5 id="cpu和gpu的区别"><a class="markdownIt-Anchor" href="#cpu和gpu的区别"></a> CPU和GPU的区别：</h5><p>  首先CPU是专为顺序串行处理而优化的几个核心组成。而GPU则由数以千计的更小、更高效的核心组成，这些核心专门为同时处理多任务而设计，可高效地处理并行任务。也就是，CPU虽然每个核心自身能力极强，处理任务上非常强悍，无奈他核心少，在并行计算上表现不佳；反观GPU，虽然他的每个核心的计算能力不算强，但他胜在核心非常多，可以同时处理多个计算任务，在并行计算的支持上做得很好。<br />  现在的计算机体系架构中，要完成CUDA并行计算，单靠GPU一人之力是不能完成计算任务的，必须借助CPU来协同配合完成一次高性能的并行计算任务。</p><h5 id="异构计算"><a class="markdownIt-Anchor" href="#异构计算"></a> 异构计算：</h5><p>  一般而言，并行部分在GPU上运行，串行部分在CPU运行，这就是异构计算。具体一点，异构计算的意思就是不同体系结构的处理器相互协作完成计算任务。CPU负责总体的程序流程，而GPU负责具体的计算任务，当GPU各个线程完成计算任务后，我们就将GPU那边计算得到的结果拷贝到CPU端，完成一次计算任务。</p><h4 id="2-cuda线程模型"><a class="markdownIt-Anchor" href="#2-cuda线程模型"></a> 2. CUDA线程模型</h4><h5 id="模型的不同层次单元"><a class="markdownIt-Anchor" href="#模型的不同层次单元"></a> 模型的不同层次单元</h5><ul><li>线程thread</li><li>线程块thread block</li><li>grid</li><li>kernel</li></ul><h5 id="sp和sm"><a class="markdownIt-Anchor" href="#sp和sm"></a> SP和SM</h5><p>  SP(Streaming Processor)是最基本的处理单元，也称为CUDA core。最后具体的指令和任务都是在SP上处理的。GPU进行并行计算，就是很多歌SP同时做处理。<br />  多个SP加上其他的一些资源组成SM(Streaming Multiprocessor)，也叫GPU大核。其他资源如：warp schedule, register, shared memory等。SM可以看做GPU的心脏（对比CPU核心），register和shared memory是SM的稀缺资源。CUDA将这些资源分配给所有驻留在SM中的threads。因此，这些有限的资源就使每个SM中的active wraps有非常严格的限制，也就限制了并行能力。每个SM包含的SP数量依据GPU架构而不同，Fermi架构GF100是32个，GF 10X是48个，Kepler架构都是192个，Maxwell都是128个。<br />  简而言之，SP是线程执行的硬件单位，SM中包含多个SP，一个GPU可以有多个SM。</p><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4><ol><li>CUDA编程之快速入门： <a href="https://www.cnblogs.com/skyfsm/p/9673960.html" target="_blank" rel="noopener">https://www.cnblogs.com/skyfsm/p/9673960.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  CUDA(Computer Unified Device Architecture)的中文全称是计算统一设备架构。&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
      <category term="计算机体系结构" scheme="http://holdfire.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="CUDA编程" scheme="http://holdfire.github.io/tags/CUDA%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>数值计算——线性代数运算程序</title>
    <link href="http://holdfire.github.io/2019/11/10/numerical-computation-blas/"/>
    <id>http://holdfire.github.io/2019/11/10/numerical-computation-blas/</id>
    <published>2019-11-09T16:22:31.000Z</published>
    <updated>2019-11-09T16:49:29.431Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><h5 id="11-blas和lapack"><a class="markdownIt-Anchor" href="#11-blas和lapack"></a> 1.1 BLAS和LAPACK</h5><p>  基础线性代数子程序(Basic Linear Algebra Subprograms , BLAS)是一个设计基本线性代数操作的数学函数标准，它定义了一组应用程序接口API标准。BLAS一般分为三级，第一级主要完成向量与向量或者向量与标量以及范数之间的运算，第二级主要涉及矩阵与向量之间的操作，第三季主要涉及矩阵于矩阵之间的操作。Netlib用firtran实现了BLAS的这些API接口，得到的库也叫作BLAS。<br />  Netlib还用fortran写了一个线性代数库叫做LAPACK（Linear Algebra Package）,其底层是BLAS，在此基础上定义了很多矩阵和向量高级运算的函数，如矩阵分解、求逆和求奇异值等。该库的运行效率比BLAS库高。为了进行C语言的开发，开发了CBLAS和CLAPACK。</p><h5 id="12-atlas和openblas"><a class="markdownIt-Anchor" href="#12-atlas和openblas"></a> 1.2 atlas和openblas</h5><p>  既然可以将BLAS和LAPACK看作是接口规范，于是开源社区实现了科学计算（矩阵计算）库atlas和openblas。它们都实现了BLAS的全部功能以及LAPACK的部分功能。<br />  Atlas （Automatically Tuned Linear Algebra Software）能根据硬件，在运行时，自动调整运行参数。Openblas在编译时根据目标硬件进行优化，生成运行效率很高的程序或者库。Openblas的优化是在编译时进行的，所以其运行效率一般比atlas要高。但这也决定了openblas对硬件依赖性高，换了机器，可能就要重新编译了。（例如A和B两台机器cpu架构、指令集不一样，操作系统一样，在A下编译的openblas库，在B下无法运行，会出现“非法指令”这样的错误）</p><h5 id="13-mkl和acml"><a class="markdownIt-Anchor" href="#13-mkl和acml"></a> 1.3 MKL和ACML</h5><p>  商业公司对BLAS和LAPACK的实现，有Intel的MKL和AMD的ACML。他们对自己的cpu架构，进行了相关计算过程的优化，实现算法效率也很高。NVIDIA针对其GPU，也推出了cuBLAS，用以在GPU上做矩阵运行。</p><h4 id="2-其他说明"><a class="markdownIt-Anchor" href="#2-其他说明"></a> 2. 其他说明</h4><p>  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;h5 id=&quot;11-blas和lapack&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#11-blas和
      
    
    </summary>
    
    
      <category term="计算数学" scheme="http://holdfire.github.io/categories/%E8%AE%A1%E7%AE%97%E6%95%B0%E5%AD%A6/"/>
    
    
      <category term="数值计算" scheme="http://holdfire.github.io/tags/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Python包学习——numpy</title>
    <link href="http://holdfire.github.io/2019/11/10/python-numpy/"/>
    <id>http://holdfire.github.io/2019/11/10/python-numpy/</id>
    <published>2019-11-09T16:07:44.000Z</published>
    <updated>2019-11-09T16:59:49.462Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><h5 id="12-numpy的array计算为什么快"><a class="markdownIt-Anchor" href="#12-numpy的array计算为什么快"></a> 1.2 Numpy的array计算为什么快？</h5><p>  numpy许多函数使用了基础线性代数子程序(Basic Linear Algebra Subprograms , BLAS)，里面拥有大量已经编写好的关于线性代数运算的程序。一般在windows下使用的是到MKL程序，linux下使用的是OpenBLAS。这些BLAS在每种操作上都进行了高度优化，例如使用AVX向量指令集。（关于BLAS参考本网站另一篇文章：<a href="">数值计算——线性代数运算程序</a>）</p><h4 id="2-numpy教程"><a class="markdownIt-Anchor" href="#2-numpy教程"></a> 2. numpy教程</h4><h5 id="21-创建数组"><a class="markdownIt-Anchor" href="#21-创建数组"></a> 2.1 创建数组</h5><ul><li>np.array操作，np.arange操作，np.linspace操作</li><li>np.zeroes操作，np.ones操作。np.eye操作</li><li>np.random.random操作</li></ul><h5 id="22-数组的加载和保存"><a class="markdownIt-Anchor" href="#22-数组的加载和保存"></a> 2.2 数组的加载和保存</h5><p>  np.save操作和np.load操作</p><h5 id="23-各种变形操作"><a class="markdownIt-Anchor" href="#23-各种变形操作"></a> 2.3 各种变形操作</h5><ul><li>reshape操作，flatten操作，</li><li>concatenate操作，stack操作，split操作</li><li>repeat操作</li><li>其他操作</li></ul><h5 id="24-索引操作"><a class="markdownIt-Anchor" href="#24-索引操作"></a> 2.4 索引操作</h5><ul><li>normal indexing：正规索引，切片得到视图，索引得到复制</li><li>bool indexing</li><li>fancy indexing</li><li>argmax操作</li></ul><h5 id="25-数组的计算"><a class="markdownIt-Anchor" href="#25-数组的计算"></a> 2.5 数组的计算</h5><p>  广播机制</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;h5 id=&quot;12-numpy的array计算为什么快&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#12
      
    
    </summary>
    
    
      <category term="编程语言" scheme="http://holdfire.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Python" scheme="http://holdfire.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>深度学习课程——TensorFlow2.0学习</title>
    <link href="http://holdfire.github.io/2019/11/09/dl-course-tf20-1/"/>
    <id>http://holdfire.github.io/2019/11/09/dl-course-tf20-1/</id>
    <published>2019-11-09T15:43:54.000Z</published>
    <updated>2019-11-09T18:19:22.391Z</updated>
    
    <content type="html"><![CDATA[<center> 第1章 TensorFlow简介与环境搭建 </center>   <h4 id="1-tensorflow简介"><a class="markdownIt-Anchor" href="#1-tensorflow简介"></a> 1. Tensorflow简介</h4><h5 id="tensorflow是什么"><a class="markdownIt-Anchor" href="#tensorflow是什么"></a> TensorFlow是什么？</h5><ul><li>采用数据流图，用于数值计算；</li><li>数据流图：节点是处理数据，边表示节点的依赖关系，边上运输张量；</li><li>节点被分配到各种计算设备上运行；</li></ul><h5 id="tensorflow的特性"><a class="markdownIt-Anchor" href="#tensorflow的特性"></a> TensorFlow的特性：</h5><ul><li>高度的灵活性</li><li>可移植性</li><li>自动求微分</li><li>多语言支持</li></ul><h5 id="tensorflow版本变迁"><a class="markdownIt-Anchor" href="#tensorflow版本变迁"></a> TensorFlow版本变迁：</h5><ul><li>201704：集成了keras</li><li>201708：添加了estimator</li><li>201711：添加了Eager execution和TensorFlow Lite（对移动端支持）</li><li>201803：推出了TF Hub，TensorFlow.js和Tensorflow Extended</li><li>201805: 支持Cloud TPU模块与管道</li><li>201806：新的分布式策略API，概率编程工具TensorFlow Probability</li><li>201808：Cloud Big Table集成</li><li>201810：侧重于可用性的API改进</li><li>2019： TensorFlow2.0发布</li></ul><h5 id="tensorflow10特性介绍"><a class="markdownIt-Anchor" href="#tensorflow10特性介绍"></a> TensorFlow1.0特性介绍</h5><ul><li>加入了XLA支持——Accelerate Linear Algebra：提升训练速度58倍</li><li>引入更高级API——tf.keras/tf.layers/tf.metrics/tf.losses</li><li>TensorFlow调试器tensorflow debugger</li><li>支持Docker镜像，引入tensorflow serving服务</li></ul><h5 id="tensorflow20主要特性"><a class="markdownIt-Anchor" href="#tensorflow20主要特性"></a> TensorFlow2.0主要特性</h5><ul><li>使用tf.keras和eager model进行更简单的模型构建</li><li>鲁棒的跨平台模型部署</li><li>keras功能API和子类API，允许差UN感觉爱你复杂的拓扑结构；</li><li>自定义训练逻辑，使用tf.GradientTape和tf。custom_gradient进行更细粒度的控制；</li><li>低层API自始至终可以与高层结合使用，完全的可定制；</li><li>高级拓展：Ragged Tensors, Tensor2Tensor；</li></ul><h5 id="tensorflow20的开发流程"><a class="markdownIt-Anchor" href="#tensorflow20的开发流程"></a> TensorFlow2.0的开发流程</h5><ul><li>使用tf.data加载数据；</li><li>使用tf.keras构建模型，也可以使用premade estimator来验证模型；<ul><li>使用tensorflow hub进行迁移学习</li></ul></li><li>使用eager mode进行运行和调试；</li><li>使用分发策略来进行分布式训练；</li><li>导出到SavedModel；</li><li>使用Tesnsoflow Server, Tensorflow Lite, Tensorflow.js部署模型。</li></ul><h4 id="2-tensorflow和pytorch的区别"><a class="markdownIt-Anchor" href="#2-tensorflow和pytorch的区别"></a> 2. Tensorflow和Pytorch的区别</h4><h5 id="21-从4个方面进行比较"><a class="markdownIt-Anchor" href="#21-从4个方面进行比较"></a> 2.1 从4个方面进行比较：</h5><ul><li>入门掌握的时间</li><li>图的创建和调试</li><li>全面性</li><li>序列化与部署</li></ul><h5 id="22-入门掌握时间"><a class="markdownIt-Anchor" href="#22-入门掌握时间"></a> 2.2 入门掌握时间</h5><p>  Tensorflow1.版本是静态图（没有eager mode的情况下就是静态图），需要额外学习很多概念：图，回话，变量，占位符等，还要写很多样板代码。<br />  Tensorflow2.0的版本的eager mode默认是打开的，使用的是动态图（运行过程中可以更改的图）。eager mode避免1.0的缺点，直接集成在python中。<br />  Pytorch构建的模型是动态图。Numpy的拓展，直接集成在python中。</p><h5 id="23-静态图和动态图"><a class="markdownIt-Anchor" href="#23-静态图和动态图"></a> 2.3 静态图和动态图</h5><p>  静态图的结构一旦确定后就不能改变，其优点是效率高。<br />  动态图的特点是调试容易。</p><p>  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;center&gt; 第1章 TensorFlow简介与环境搭建 &lt;/center&gt;   
&lt;h4 id=&quot;1-tensorflow简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-tensorflow简介&quot;&gt;&lt;/a&gt; 1. Tensorflow简介
      
    
    </summary>
    
    
      <category term="深度学习" scheme="http://holdfire.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="TensorFlow" scheme="http://holdfire.github.io/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>dl-AndrewNGDL-chapter1</title>
    <link href="http://holdfire.github.io/2019/11/08/dl-AndrewNGDL-chapter1/"/>
    <id>http://holdfire.github.io/2019/11/08/dl-AndrewNGDL-chapter1/</id>
    <published>2019-11-08T11:44:44.000Z</published>
    <updated>2019-11-08T11:44:44.863Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Linux——文件系统挂载</title>
    <link href="http://holdfire.github.io/2019/11/08/linux-file-mount/"/>
    <id>http://holdfire.github.io/2019/11/08/linux-file-mount/</id>
    <published>2019-11-08T10:23:16.000Z</published>
    <updated>2019-11-08T10:26:11.658Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  &lt;/p&gt;

      
    
    </summary>
    
    
      <category term="操作系统" scheme="http://holdfire.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Linux" scheme="http://holdfire.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Windows——环境变量path</title>
    <link href="http://holdfire.github.io/2019/11/08/windows-environment-path/"/>
    <id>http://holdfire.github.io/2019/11/08/windows-environment-path/</id>
    <published>2019-11-08T09:10:52.000Z</published>
    <updated>2019-11-08T09:15:07.395Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  windows环境变量</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  windows环境变量&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="操作系统" scheme="http://holdfire.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Windows" scheme="http://holdfire.github.io/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>Windows——cmd命令</title>
    <link href="http://holdfire.github.io/2019/11/08/windows-cmd-commands/"/>
    <id>http://holdfire.github.io/2019/11/08/windows-cmd-commands/</id>
    <published>2019-11-08T09:04:34.000Z</published>
    <updated>2019-11-08T10:25:23.434Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1简介"><a class="markdownIt-Anchor" href="#1简介"></a> 1.简介</h4><h5 id="11-cmd命令解释器"><a class="markdownIt-Anchor" href="#11-cmd命令解释器"></a> 1.1 cmd命令解释器</h5><p>  cmd命令行解释器是一个单独的软件程序，它可在用户和操作系统之间提供直接的通讯。命令行解释器是解释器的一种，用于对命令行进行解释执行。<br />  cmd.exe命令行解释器环境由确定命令行解释器和操作系统行为的变量进行定义。可以使用两种类型的环境变量（系统和局部）来定义命令行解释器环境或整个操作系统环境的行为。系统环境变量定义全局操作系统环境的行为。局部环境变量定义Cmd.exe当前实例环境的行为。</p><h5 id="12-cmd可执行程序的类型及存放位置"><a class="markdownIt-Anchor" href="#12-cmd可执行程序的类型及存放位置"></a> 1.2 cmd可执行程序的类型及存放位置</h5><p>  以dos系统而言，可执行程序大约可以细分为五类，依照执行优先级由高到低排列如下。其中，内部系统命令存放在。可执行程序在当前目和环境变量下进行搜索。</p><ul><li>（1）DOSKEY宏命令（预先驻留内存）</li><li>（2）COMMAND.COM中的内部命令（根据内存的环境随时进驻内存）</li><li>（3）以com为扩展名的可执行程序（<a href="http://xn--command-ed9q.com" target="_blank" rel="noopener">由command.com</a> 直接载入内存）</li><li>（4）以exe位扩展名的可执行程序（<a href="http://xn--command-ed9q.com" target="_blank" rel="noopener">由command.com</a> 重定位后载入内存）</li><li>（5）以bat位扩展名的批处理程序（<a href="http://xn--command-ed9q.com" target="_blank" rel="noopener">由command.com</a> 解释分析，根据其内容按优先级顺序调用第2，3，4，5种可执行程序，分析一行，执行一行，文件本身不载入内存）</li></ul><h5 id="13-执行命令时的搜索顺序"><a class="markdownIt-Anchor" href="#13-执行命令时的搜索顺序"></a> 1.3 执行命令时的搜索顺序</h5><p>（1）如果该命令不带后缀</p><ul><li>首先在无后缀的系统命令中搜索；</li><li>然后在当前目录中查找该命令+.exe、.msc、.bat等后缀的可执行文件或批处理文件；</li><li>在环境变量那些目录中按上一条的规则搜索；<br />（2）如果该命令带后缀</li><li>首先在当前目录中搜索该文件，若存在，如果该文件是一个可执行文件或批处理文件，则执行之，如果是其他一般文件则用与该类型文件关联的默认程序打开它；</li><li>若当前目录不存在该文件,则在当前目录中查找是否存在以该文件名+可执行文件或批处理文件后缀（.exe、.bat、.msc等）命名的文件，如果找到了则执行之;</li><li>如果在当前目录中上述两种情况都未找到，才在环境变量所设置的那些目录中按上述顺序搜寻。先是按cmd命令所给的准确文件名查找，如果有，是程序或批处理则执行，是其它文件就用默认程序打开；</li><li>如果在环境变量目录中未找到该文件，再在环境变量目录中查找是否存在该文件名+可执行文件或批处理文件后缀（.exe、.bat、.msc等）的文件，如果找到了则执行之。</li><li>如果还是没有，则只好报错，该命令 is not recognised as an internal or external command, operable program or batch file.<br />（3）如果cmd命令中带路径，很明显只在指定目录中寻找文件，而不会到环境变量中去找，如果文件名不带后缀，则跟第一种情况一样，在指定目录中寻找这个名称的可执行文件或批处理文件执行，找不到报错；如果带后缀，若存在，则执行或用默认程序打开，若不存在，寻找该文件名+可执行文件或批处理文件后缀的文件来执行，找不到报错。</li></ul><h4 id="2-内置命令"><a class="markdownIt-Anchor" href="#2-内置命令"></a> 2. 内置命令</h4><h5 id="21-文件和目录相关操作"><a class="markdownIt-Anchor" href="#21-文件和目录相关操作"></a> 2.1 文件和目录相关操作</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd dir                   <span class="comment"># 切换到该目录下</span></span><br><span class="line">mkdir dir                <span class="comment"># 创建新目录</span></span><br></pre></td></tr></table></figure><h5 id="22-网络相关"><a class="markdownIt-Anchor" href="#22-网络相关"></a> 2.2 网络相关</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipcofig                  # 查看当前IP配置</span><br><span class="line">ping 域名/IP地址          # 查看网络连接是否正常</span><br></pre></td></tr></table></figure><h5 id="23-文件搜索相关"><a class="markdownIt-Anchor" href="#23-文件搜索相关"></a> 2.3 文件搜索相关</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">find / -name file1        # 从 &apos;/&apos; 开始进入根文件系统搜索文件和目录</span><br><span class="line">find / -name \*.rpm       # 搜索以&apos;.rpm&apos;结尾的文件并定义其权限</span><br><span class="line">locate \*.ps              # 寻找以 &apos;.ps&apos; 结尾的文件 - 先运行 &apos;updatedb&apos; 命令</span><br><span class="line">where command             # 查找该命令所在路径</span><br><span class="line">whereis halt              # 显示一个二进制文件、源码或man的位置</span><br><span class="line">which halt                # 显示一个二进制文件或可执行文件的完整路径</span><br></pre></td></tr></table></figure><h4 id="3-概念区别"><a class="markdownIt-Anchor" href="#3-概念区别"></a> 3. 概念区别</h4><h5 id="31-shell的定义"><a class="markdownIt-Anchor" href="#31-shell的定义"></a> 3.1 Shell的定义</h5><p>  操作系统可以分成核心（kernel）和Shell（外壳）两部分，其中，Shell是操作系统与外部的主要接口，位于操作系统的外层，为用户提供与操作系统核心沟通的途径。Shell是一个命令解释器(也是一种应用程序)，处于内核和用户之间，负责把用户的指令传递给内核并且把执行结果回显给用户。同时，shell也可以作为一门强大的编程语言。<br />  Shell分为图形界面shell和命令行shell两大类，如windows的资源管理器explorer.exe和cmd命令窗口，linux系统中的bash。</p><h5 id="32-cmd和文件资源管理器"><a class="markdownIt-Anchor" href="#32-cmd和文件资源管理器"></a> 3.2 cmd和文件资源管理器</h5><p>  在windows系统中见到的桌面即explorer.exe（文件资源管理器）是 <strong><font color="red">图形shell</font></strong>，而cmd就是 <strong><font color="red">命令行shell</font></strong>。</p><h5 id="33-cmd和dos"><a class="markdownIt-Anchor" href="#33-cmd和dos"></a> 3.3 cmd和dos</h5><p>  dos本身是一个系统，这是cmd与dos的最大区别：一个只是接口、一个是操作系统。只是cmd中的某些命令和dos中的命令相似，因此很多人把二者混为一谈。cmd属于windows系统的一部分，dos本身就是一个系统，在dos系统下可以删除，修复windows系统，而在cmd下则不行。</p><h5 id="34-cmd和bash"><a class="markdownIt-Anchor" href="#34-cmd和bash"></a> 3.4 cmd和bash</h5><p>  bash是Linux和Unix下的shell，如果真的想试用，可以在MS windows下安装Cygwin环境，然后再在其下使用。 这时需要注意，Cygwin环境下跟真实的Linux或Unix是有区别的，一些命令会运行不正常。最直接的体验，还是使用Linux来得贴心，几乎可以做任何事情。如果想在MS Windows下使用Shell，建议还是使用微软的PowerShell，它能提供给你操作MS windows的完全功能。</p><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4><ol><li>cmd命令搜索顺序：<a href="https://www.cnblogs.com/idisposable/p/5137808.html" target="_blank" rel="noopener">https://www.cnblogs.com/idisposable/p/5137808.html</a></li><li>shell，dos，cmd和脚本语言：<a href="https://www.cnblogs.com/lishanyang/p/9224988.html" target="_blank" rel="noopener">https://www.cnblogs.com/lishanyang/p/9224988.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1简介&quot;&gt;&lt;/a&gt; 1.简介&lt;/h4&gt;
&lt;h5 id=&quot;11-cmd命令解释器&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#11-cmd命令解释器&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="操作系统" scheme="http://holdfire.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Windows" scheme="http://holdfire.github.io/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>Python-conda和Anaconda介绍</title>
    <link href="http://holdfire.github.io/2019/11/08/python-anaconda/"/>
    <id>http://holdfire.github.io/2019/11/08/python-anaconda/</id>
    <published>2019-11-08T07:20:56.000Z</published>
    <updated>2019-11-08T07:25:44.688Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  &lt;/p&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>编译原理——gcc,g++,make和cmake的区别</title>
    <link href="http://holdfire.github.io/2019/11/08/complie-make-cmake/"/>
    <id>http://holdfire.github.io/2019/11/08/complie-make-cmake/</id>
    <published>2019-11-07T18:32:53.000Z</published>
    <updated>2019-11-07T18:53:17.652Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-gcc和g的区别"><a class="markdownIt-Anchor" href="#1-gcc和g的区别"></a> 1. gcc和g++的区别</h4><p>  二者的区别在于：<br />（1）对于.c的文件，gcc把它当成是c程序，g<ins>当做是c</ins>程序；对于.cpp的文件，两者都会认为是c<ins>程序。<br />（2）编译可以用gcc或g</ins>，链接可以用gcc-lstdc<ins>或者g</ins>。<br />（3）如果后缀为.C的文件定义了_cplusplus宏，gcc编译器认为该宏是未定义的，否则就是已定义的。<br />（4）无论是gcc还是g++，当源文件中用extern &quot;C&quot;时，都是以C的命名方式来为symbol命名的；否则，都以c<ins>的方式命名。<br />（5）在编译阶段，g</ins>是调用gcc的。</p><h4 id="2-make和cmake的区别"><a class="markdownIt-Anchor" href="#2-make和cmake的区别"></a> 2. make和cmake的区别</h4><p>  但如果源文件太多，一个个编译会太麻烦。于是人们设计了一个类似批处理的程序来来批量编译源文件，于是就有了make工具，但你需要编写一个规则文件，make依据它来批处理编译，这个文件就是<strong>makefile</strong>。所以编写makefile也是一个程序员所必备的技能。<br />  对于一个大型工程，编写makefile是一件复杂的事。于是人们又设计了一个读入所有源文件后，自动生成makefile的工具，这就是cmake，它能够输出makefile或者project文件。但是程序员还是要编写<strong>cmakefile</strong>，它是cmake所依据的规则。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-gcc和g的区别&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-gcc和g的区别&quot;&gt;&lt;/a&gt; 1. gcc和g++的区别&lt;/h4&gt;
&lt;p&gt;  二者的区别在于：&lt;br /&gt;
（1）对于.c的文件，gcc把它当成是c程序，g&lt;ins
      
    
    </summary>
    
    
      <category term="编译原理" scheme="http://holdfire.github.io/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
      <category term="编程语言" scheme="http://holdfire.github.io/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="编译原理" scheme="http://holdfire.github.io/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
      <category term="C++" scheme="http://holdfire.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>图像特征——基于描述子的图像对齐</title>
    <link href="http://holdfire.github.io/2019/11/07/cv-imageFeature-3alignment/"/>
    <id>http://holdfire.github.io/2019/11/07/cv-imageFeature-3alignment/</id>
    <published>2019-11-07T11:41:28.000Z</published>
    <updated>2019-11-07T11:54:28.817Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  在keypoingts和descriptors均已生成，特征点已经匹配过后，根据matched特征点对可以做图片对齐</p><h4 id="2-ransac算法"><a class="markdownIt-Anchor" href="#2-ransac算法"></a> 2. RANSAC算法</h4><p>  RANSAC算法（Random sample consensus:RANSAC，也叫随机抽样一致算法）用来筛选匹配点，从而计算单应性矩阵。该算法能够有效地去除误差很大的点，并且这些点不计入模型的计算之中。<br />RANSAC算法经常用于计算机视觉，例如同时求解相关问题与估计立体摄像机的基础矩阵，在图像拼接时求变换矩阵的时候。在SLAM中经常被用于虑除误匹配。</p><h5 id="21-算法步骤"><a class="markdownIt-Anchor" href="#21-算法步骤"></a> 2.1 算法步骤</h5><p>  在数据误差比较小的情况下，可以使用最小二乘法。但针对噪声很大的数据集的时候，容易出问题。算法的框架如下：<br />在数据中随机的选择几个点设定为内群（也就是用来计算模型的点）<br />用这些选择的数据计算出一个模型<br />把其它刚才没选到的点带入刚才建立的模型中，计算是否为内群（也就是看这些点是否符合模型，如果符合模型的话，将新的点也计入内群）<br />如果此时的内群数量足够多的话，可以认为这个模型还算OK，那么就用现在的内群数据重新计算一个稍微好些的模型。<br />重复以上步骤，最后，我们保留那个内群数量最多的模型。<br />在得到了众多的匹配点以后，使用RANSAC算法，每次从中筛选四个随机的点，然后求得H矩阵，不断的迭代，直到求得最优的Homography矩阵为止。</p><h5 id="22-单应性矩阵homography"><a class="markdownIt-Anchor" href="#22-单应性矩阵homography"></a> 2.2 单应性矩阵Homography</h5><p>  采用RANSAC算法寻找一个最佳单应性矩阵H，矩阵大小为3×3。RANSAC目的是找到最优的参数矩阵使得满足该矩阵的数据点个数最多，通常令h33=1h33=1来归一化矩阵。由于单应性矩阵有8个未知参数，至少需要8个线性方程求解，对应到点位置信息上，一组点对可以列出两个方程，则至少包含4组匹配点对。</p><h5 id="23-ransac算法优缺点"><a class="markdownIt-Anchor" href="#23-ransac算法优缺点"></a> 2.3 RANSAC算法优缺点：</h5><p>  RANSAC的优点是它能鲁棒的估计模型参数。例如，它能从包含大量局外点的数据集中估计出高精度的参数。RANSAC的缺点是它计算参数的迭代次数没有上限；如果设置迭代次数的上限，得到的结果可能不是最优的结果，甚至可能得到错误的结果。<br />RANSAC只有一定的概率得到可信的模型，概率与迭代次数成正比。RANSAC的另一个缺点是它要求设置跟问题相关的阀值。 RANSAC只能从特定的数据集中估计出一个模型，如果存在两个（或多个）模型，RANSAC不能找到别的模型。</p><h4 id="3-gms算法"><a class="markdownIt-Anchor" href="#3-gms算法"></a> 3. GMS算法</h4><p>  GMS（CVPR2017论文：Grid-based Motion Statisticsfor Fast, Ultra-robust Feature Correspondence ）的方法实际上是<strong>消除错误匹配</strong>的一种方案，比如可以替换ransac。算法执行的大致流程是：先执行任意一种特征点的检测和特征点的描述子计算，论文中采用的是ORB特征。然后执行暴力匹配BF，最后执行GMS以消除错误匹配。<br />opencv的ransac非常耗时，这个GMS则非常快，比opencv的ransac快好几倍。在同样特征点执行错误消除的时候要比openCV的ransac快。实际上ransac可以优化到非常快，至少可以比openCV的ransac要快10倍以上。在同样特征点个数的情况下，用ORB+BF+GMS 的时间 小于 SIFT + RANSAC的时间。</p><h5 id="算法特点"><a class="markdownIt-Anchor" href="#算法特点"></a> 算法特点：</h5><p>  该论文认为运动的平滑性导致了匹配的特征点周围的区域有较多匹配的点，因此可以通过计数周围区域的匹配点个数来判断一个匹配正确与否。之前的特征匹配的论文多认为匹配的质量受特征不变性和区别是否明显的影响，本文从一个新的角度来分析，认为原始特征的数量也能够影响匹配的质量。而找到更多特征显然比设计全新的匹配器更加简单，GMS就是这样一个简捷的解决方法，综合来看论文的贡献在于：将运动平滑性转化为统计问题以判别错误的匹配，使得困难场景上的匹配更高效。一个有效的基于网格的打分器，能够与实时的特征匹配器结合证明了GMS系统具有更好的效果(SIFT,SURF,LIFT)</p><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4><p>使用Python中的SIFT算法进行图像校准 <a href="https://www.jianshu.com/p/f1b97dacc501" target="_blank" rel="noopener">https://www.jianshu.com/p/f1b97dacc501</a><br />RANSAC算法理解1： <a href="https://blog.csdn.net/robinhjwy/article/details/79174914" target="_blank" rel="noopener">https://blog.csdn.net/robinhjwy/article/details/79174914</a><br />RANSAC算法理解2： <a href="https://blog.csdn.net/fandq1223/article/details/53175964" target="_blank" rel="noopener">https://blog.csdn.net/fandq1223/article/details/53175964</a><br />GMS论文解读： <a href="https://blog.csdn.net/kevin_zhao_zl/article/details/89810718" target="_blank" rel="noopener">https://blog.csdn.net/kevin_zhao_zl/article/details/89810718</a><br />GMS算法特点介绍：<a href="https://zhuanlan.zhihu.com/p/27131143" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27131143</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  在keypoingts和descriptors均已生成，特征点已经匹配过后，根据matched特征点对可以做图片对齐&lt;/p&gt;

      
    
    </summary>
    
    
    
      <category term="图像特征" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81/"/>
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>图像特征——基于描述子的图像匹配</title>
    <link href="http://holdfire.github.io/2019/11/07/cv-imageFeature-2matcht/"/>
    <id>http://holdfire.github.io/2019/11/07/cv-imageFeature-2matcht/</id>
    <published>2019-11-07T11:41:06.000Z</published>
    <updated>2019-11-07T11:54:23.439Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  在keypoingts和descriptors均已生成的前提下，opencv的匹配步骤：<br />（1）生成匹配器matcher：DescriptorMatcher，BFMatcher，FlannMatcher；<br />（2）选择匹配函数类型：match，knnMatch，radiusMatch；<br />（3）上述匹配函数存在的重载函数，来实现一对一或者一对多<br />  特征描述是实现图像匹配与图像搜索必不可少的步骤，比较有代表性的特征描述子是浮点型特征描述子和二进帽字符串特征描述子。像SIFT与SURF算法用梯度统计直方图来描述的描述子都属于浮点型特征描述子。但它们计算起来，算法复杂，效率较低，所以后来就出现了许多新型的特征描述算法，如BRIEF。后来很多二进制串描述子ORB，BRISK，FREAK等都是在它上面的基础上的改进。</p><h4 id="2-暴力匹配算法brute-force"><a class="markdownIt-Anchor" href="#2-暴力匹配算法brute-force"></a> 2. 暴力匹配算法Brute Force</h4><p>  以二进制串特征描述子匹配为例，ORB算法最大的特点就是计算速度快 。 这首先得益于使用FAST检测特征点，FAST的检测速度正如它的名字一样是出了名的快。再次是使用BRIEF算法计算描述子，该描述子特有的2进制串的表现形式不仅节约了存储空间，而且大大缩短了匹配的时间。<br />例如特征点A、B的描述子如下。<br />A：10101011<br />B：10101010<br />我们设定一个阈值，比如80%。当A和B的描述子的相似度大于90%时，我们判断A,B是相同的特征点，即这2个点匹配成功。在这个例子中A,B只有最后一位不同，相似度为87.5%，大于80%。则A和B是匹配的。<br />我们将A和B进行异或操作就可以轻松计算出A和B的相似度。而异或操作可以借组硬件完成，具有很高的效率，加快了匹配的速度。</p><h4 id="3-聚类算法"><a class="markdownIt-Anchor" href="#3-聚类算法"></a> 3. 聚类算法</h4><h4 id="4-flann算法"><a class="markdownIt-Anchor" href="#4-flann算法"></a> 4. flann算法</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  在keypoingts和descriptors均已生成的前提下，opencv的匹配步骤：&lt;br /&gt;
（1）生成匹配器matc
      
    
    </summary>
    
    
    
      <category term="图像特征" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81/"/>
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>自动机器学习AutoML和神经架构搜索NAS（1）</title>
    <link href="http://holdfire.github.io/2019/11/07/dl-advanced-NASandAutoML1/"/>
    <id>http://holdfire.github.io/2019/11/07/dl-advanced-NASandAutoML1/</id>
    <published>2019-11-07T02:02:55.000Z</published>
    <updated>2019-11-07T03:34:03.422Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  神经架构搜索(Neural Architecture Search, NAS)是一种搜索出最优神经网络架构的算法。它的工作流程通常从定义一组神经网络可能会用到的“建筑模块”开始，比如2018年Google Brain关于NASNet的论文，就为图像识别网络总结了多种常用的卷积池和池化模块。论文：<a href="https://arxiv.org/abs/1707.07012" target="_blank" rel="noopener">Learning Transferable Architectures for Scalable Image Recognition</a><br />  NAS算法用一个循环神经网络(RNN)作为控制器，从这些模块中挑选，然后将它们放在一起，来创造某种端到端地架构。然后训练这个新网络直至收敛，得到在验证集上的准确率，这个准确率随后会用来通过策略梯度更新控制器，让控制器生成架构的水平越来越高。</p><h4 id="2-架构搜索的进展"><a class="markdownIt-Anchor" href="#2-架构搜索的进展"></a> 2. 架构搜索的进展</h4><h5 id="渐进式神经架构搜索pnas"><a class="markdownIt-Anchor" href="#渐进式神经架构搜索pnas"></a> 渐进式神经架构搜索PNAS</h5><p>  论文：<a href="https://arxiv.org/abs/1712.00559" target="_blank" rel="noopener">Progressive Neural Architecture Search</a></p><h5 id="高效神经架构搜索enas"><a class="markdownIt-Anchor" href="#高效神经架构搜索enas"></a> 高效神经架构搜索ENAS</h5><p>  论文：<a href="http://arxiv.org/abs/1802.03268" target="_blank" rel="noopener">Efficient Neural Architecture Search via Parameter Sharing</a></p><h4 id="架构搜索的开源项目和商业产品"><a class="markdownIt-Anchor" href="#架构搜索的开源项目和商业产品"></a> 架构搜索的开源项目和商业产品</h4><h5 id="开源项目"><a class="markdownIt-Anchor" href="#开源项目"></a> 开源项目</h5><h5 id="商业产品"><a class="markdownIt-Anchor" href="#商业产品"></a> 商业产品</h5><p>  Google提供的Cloud AutoML</p><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4><ol><li>一文看懂AutoML和NAS：<a href="https://zhuanlan.zhihu.com/p/42924585" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/42924585</a></li><li>AutoML和NAS的调研（CVPR2019）:<a href="https://blog.csdn.net/soulmeetliang/article/details/93002244" target="_blank" rel="noopener">https://blog.csdn.net/soulmeetliang/article/details/93002244</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  神经架构搜索(Neural Architecture Search, NAS)是一种搜索出最优神经网络架构的算法。它的工作流程
      
    
    </summary>
    
    
      <category term="深度学习" scheme="http://holdfire.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习前沿" scheme="http://holdfire.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%89%8D%E6%B2%BF/"/>
    
  </entry>
  
  <entry>
    <title>自动机器学习AutoML和神经架构搜索NAS（2）</title>
    <link href="http://holdfire.github.io/2019/11/07/dl-advanced-NASandAutoML2/"/>
    <id>http://holdfire.github.io/2019/11/07/dl-advanced-NASandAutoML2/</id>
    <published>2019-11-07T02:02:55.000Z</published>
    <updated>2019-11-07T03:29:31.705Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  </p><h4 id="2nas算法搜索图像分类backbone"><a class="markdownIt-Anchor" href="#2nas算法搜索图像分类backbone"></a> 2.NAS算法搜索图像分类backbone</h4><p>  </p><h4 id="3-nas算法搜索物体检测backbone"><a class="markdownIt-Anchor" href="#3-nas算法搜索物体检测backbone"></a> 3. NAS算法搜索物体检测backbone</h4><p><code>2019 NeurIPS: 旷视研究院提出DetNAS</code><br />  这是首个用于设计更好的物体检测器Backbone的神经网络搜索方法，由DetNet搜索出的框架在COCO上的性能超越了ResNet-50和ResNet-101，且模型计算量更低。<br />论文：<a href="https://arxiv.org/abs/1903.10979?context=cs" target="_blank" rel="noopener">DetNAS:Backbone Search for Object Detection</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h4 id=&quot;2nas算法搜索图像分类backbone&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot;
      
    
    </summary>
    
    
      <category term="深度学习" scheme="http://holdfire.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习前沿" scheme="http://holdfire.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%89%8D%E6%B2%BF/"/>
    
  </entry>
  
  <entry>
    <title>图像检索——特征编码与聚合</title>
    <link href="http://holdfire.github.io/2019/11/06/cv-imageRetrieval-2encodeFeatures/"/>
    <id>http://holdfire.github.io/2019/11/06/cv-imageRetrieval-2encodeFeatures/</id>
    <published>2019-11-06T12:23:06.000Z</published>
    <updated>2019-11-07T11:36:16.177Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><h4 id="2-bow词袋模型"><a class="markdownIt-Anchor" href="#2-bow词袋模型"></a> 2. BoW词袋模型</h4><p>  BOF算法(Bag of Features)是首先将所有图像的所有特征点进行聚类，然后根据聚类中心对检索库的每张图片做了一个编码。然后将query的图像和图像库中中每幅图的BOF向量求夹角，最小的即为匹配对象。BOF算法解决的是：每张图片的特征点太多，两张图片做起匹配来花费时间太长这一问题。<br />  BOF算法的流程如下所示：<br />（1）所有图像的局部特征提取。<br />（2）构建视觉词典：使用k-means算法从所有特征点中生成类心。<br />（3）生成原始的的BOF：判断图像的每个特征点与哪个类心最近，最近则放入该类心，最后将生成一列频数表，即初步的无权BOF。<br />（4）引入TF-IDF权值：对频数表加上权重，生成最终的bof。（因为每个类心对图像的影响不同。比如超市里条形码中的第一位总是6，它对辨别产品毫无作用，因此权重要减小）。<br />（5）对query进来的图像也生成带TF-IDF权值的BOF。<br />（6）将query的Bof向量与图像库中每幅图的Bof向量求夹角，夹角最小的即为匹配对象。</p><h4 id="3-vlad算法"><a class="markdownIt-Anchor" href="#3-vlad算法"></a> 3. VLAD算法</h4><p>  Jégou提出VLAD(vector of locally aggregated descriptors)，其方法是如同BOF先建立出含有k个visual word的codebook，而不同于BOF将一个local descriptor用NN分类到最近的visual word中，VLAD所采用的是计算出local descriptor和每个visual word在每个分量上的差距，将每个分量的差距形成一个新的向量来代表图片。</p><h4 id="4-fv算法"><a class="markdownIt-Anchor" href="#4-fv算法"></a> 4. FV算法</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;h4 id=&quot;2-bow词袋模型&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#2-bow词袋模型&quot;&gt;&lt;/
      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://holdfire.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>图像特征——CNN特征</title>
    <link href="http://holdfire.github.io/2019/11/06/cv-imageFeature-1cnnFeatures/"/>
    <id>http://holdfire.github.io/2019/11/06/cv-imageFeature-1cnnFeatures/</id>
    <published>2019-11-06T12:16:46.000Z</published>
    <updated>2019-11-07T11:54:14.904Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  &lt;/p&gt;

      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://holdfire.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像特征" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81/"/>
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>图像特征——全局特征描述</title>
    <link href="http://holdfire.github.io/2019/11/06/cv-imageFeature-1globalFeatures/"/>
    <id>http://holdfire.github.io/2019/11/06/cv-imageFeature-1globalFeatures/</id>
    <published>2019-11-06T12:05:02.000Z</published>
    <updated>2019-11-07T11:54:09.943Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  用来描述图像全局特征的指标主要有：颜色特征、形状特征和纹理特征。目前形状特征在图像检索中使用相对较少，本文不予介绍。</p><h4 id="2-颜色特征"><a class="markdownIt-Anchor" href="#2-颜色特征"></a> 2. 颜色特征</h4><p>  颜色特征是统计图片不同颜色的分布来描述整张图片，颜色分布图计算简单，对平移、旋转尺度缩放具有不变性。<br />  灰度分布图损失了颜色信息，RGB分布图和人类对视觉的感知差别较大，也不建议使用。<strong><font color="red">HSV和Lab色彩空间</font></strong> 和人类主观感知更为接近。常用于图像检索的颜色特征包括：直方图、累积直方图、平均灰度级等。其中，基于累积直方图的图像检索性能最优。</p><h4 id="3-纹理特征"><a class="markdownIt-Anchor" href="#3-纹理特征"></a> 3. 纹理特征</h4><p>  全局特征信息又称为Gist信息，为场景的低维签名向量。采用全局特征信息对场景进行识别与分类不需要对图像进行分割和局部特征提取，可以实现快速场景识别与分类。（Gist特征仅指纹理特征吗？）<br />  纹理特征是指物体表面共有的内在特性，其包含了物体表面结构组织排列的重要信息及其与周围物体的联系。当检索在粗细和疏密等方面有较大差别的图像时，利用纹理特征是一种行之有效的方法。有实验结果表明，Gabor小波能够较好地兼顾信号在时域和频域中的分辨能力，是图像检索中的最佳特征之一。</p><p>  <strong><font color="red">小波变换</font></strong>：2004年，Torralba等采用小波图像分解算法来提取输入图像的全局特征信息。首先将输入图像分解成<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">4\times4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span>个小区域子块，然后对每个小区域子块从6个方向和4个尺度采用小波滤波来提取图像的纹理特征信息。每幅图片的Gist信息为对各个小区域模块中滤波后的平均输出，得到384维GIST向量，然后采用PCA算法降维至80维。最后，根据各场景的Gist向量得到训练集Gist向量的最小欧氏距离来确定场景的类别。<br />  <strong><font color="red">Tamura纹理：</font></strong>：Tamura纹理特征包括6个指标：粗糙度(Courseness)、对比度(Contrast)、方向度(Directionality)、线性度(Linelikeness)、规则度(Regularity)、粗略度(Roughness)。一般论文里面只用前三个特征，说前面三个特征是线性无关的，后面三个特征和前面三个特征是线性相关的，因此只采用前三个特征。<br />  <strong><font color="red">Gabor变换</font></strong>：<strong>GIST512计算:</strong>（1）32个Gabor滤波在4个尺度，8个方向上进行卷积，得到32个个输入图像大小一致的feature map；（2）把每个feature map分成<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">4 \times 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span>共16个区域，计算每个区域内的均值；（3）计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>16</mn><mo>×</mo><mn>32</mn></mrow><annotation encoding="application/x-tex">16\times32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">2</span></span></span></span>个均值的结果，就得到了512维的GIST特征。不同维度的GIST特征在于Gabor滤波器的个数，确切的说是滤波器方向和尺寸的不同。<br />  <strong><font color="red">灰度共生矩阵</font></strong>：灰度共生矩阵(Gray-Leavel Co-currence Matrix, GLCM)是像素灰度在空间位置上的反复出现形成图像的纹理。是描述具有某种空间位置关系两个像素灰度的联合分布，是一种二阶统计量。<br />  <strong><font color="red">纹理谱</font></strong>：</p><h4 id="4-感知哈希算法"><a class="markdownIt-Anchor" href="#4-感知哈希算法"></a> 4. 感知哈希算法</h4><p>  <br />基于低频的均值哈希aHash<br />感知哈希pHash<br />差异哈希算法dHash</p><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4><ol><li>HSV色彩空间映射：<a href="https://blog.csdn.net/guanjungao/article/details/26617927" target="_blank" rel="noopener">https://blog.csdn.net/guanjungao/article/details/26617927</a></li><li>三种感知哈希算法：<a href="https://blog.csdn.net/weierqiuba/article/details/71305692" target="_blank" rel="noopener">https://blog.csdn.net/weierqiuba/article/details/71305692</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  用来描述图像全局特征的指标主要有：颜色特征、形状特征和纹理特征。目前形状特征在图像检索中使用相对较少，本文不予介绍。&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://holdfire.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像特征" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81/"/>
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>图像特征——局部特征点检测和描述</title>
    <link href="http://holdfire.github.io/2019/11/06/cv-imageFeature-1localFeatures/"/>
    <id>http://holdfire.github.io/2019/11/06/cv-imageFeature-1localFeatures/</id>
    <published>2019-11-06T11:51:49.000Z</published>
    <updated>2019-11-07T11:56:10.176Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  局部特征代表了图像的局部特性，一幅图像中旺旺能提取出若干个数量不等的局部特征，这些局部特征组合起来代表了整幅图像的特征分布。<br />局部特征是从图像局部区域中抽取的特征，包括边缘、角点、线、曲线和特别属性的区域等，常见的局部特征包括角点类和区域类两大类描述方式。<br />  斑点通常是指与周围有着颜色和灰度差别的区域。斑点通常是指与周围有着颜色和灰度差别的区域，在实际地图中如一颗树是一个斑点，一块草地是一个斑点，一栋房子也可以是一个斑点。斑点通常和关键点(key point)，兴趣点(intrest point)以及特征点(feature point)表示同一个概念。<br />  角点可以从两个不同角度定义：角点是两个边缘的交点；角点是领域内具有两个主方向的特征点。角点所在的领域通常也是图像中稳定的，信息丰富的区域，这些领域可能具有某些特性，比如旋转不变性，尺度不变性，仿射不变性和光照亮度不变性。<br />  边缘检测寻找的就是一阶微分的极值点，当然一阶微分的极值点当然是二阶微分的过零点，所以边缘检测有两种常用的方法：一是基于一阶微分的，寻找极值点，如Roberts,Canny,Prewitt等等；另一类是基于二阶微分的，寻找过零点，如LoG等。<br />  openCV中</p><h4 id="2-局部特征点检测keypoints"><a class="markdownIt-Anchor" href="#2-局部特征点检测keypoints"></a> 2. 局部特征点检测keypoints</h4><p><code>角点检测：</code><br />  <strong><font color="red">Harris角点：</font></strong> Harris角点检测是一种基于图像灰度的一阶导数矩阵检测方法。检测器的主要思想是局部自相似性/自相关性，即在某个局部窗口内图像块与在各个方向微小移动后的窗口内图像块的相似性。在像素点的邻域内，导数矩阵描述了数据信号的变化情况。假设在像素点邻域内任意方向上移动块区域，若强度发生了剧烈变化，则变化处的像素点为角点。<br />  <strong><font color="red">FAST角点：</font></strong> FAST算法检基于特征点周围的图像灰度值，检测候选特征点周围一圈的像素值，如果候选点周围领域内有足够多的像素点与该候选点的灰度值差别够大，则认为该候选点为一个特征点。候选点周围的圆的选取半径是一个很重要的参数，这里为了简单高效，采用半径为3，共有16个周边像素需要比较。圆周上如果有连续n个像素点的灰度值比P点的灰度值大或者小，则认为P为特征点。一般n设置为12。</p><p><code>斑点检测：</code><br />  <strong><font color="red">DOH斑点：</font></strong><br />  <strong><font color="red">GLOH斑点；</font></strong><br />  <strong><font color="red">LOG斑点：</font></strong></p><h4 id="3-局部特征描述descriptors"><a class="markdownIt-Anchor" href="#3-局部特征描述descriptors"></a> 3. 局部特征描述descriptors</h4><p><code>局部纹理描述——针对整张图片：</code><br />  <strong><font color="red">HOG特征：</font></strong> HOG(Histogram of Gradient)计算和统计图像局部区域的梯度直方图来构成描述。（1）将图像灰度化；（2）采用Gamma校正法对输入图像进行颜色空间的标准化（归一化）；目的是调节图像的对比度，降低图像局部的阴影和光照变化所造成的影响，同时可以抑制噪音的干扰；（3）计算图像每个像素的梯度（包括大小和方向）；主要是为了捕获轮廓信息，同时进一步弱化光照的干扰。（4）将图像划分成小cells（例如<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>6</mn><mo>×</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">6 \times 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span>像素/cell）；（5）统计每个cell的梯度直方图（不同梯度的个数），即可形成每个cell的descriptor；（6）将每几个cell组成一个block（例如3*3个cell/block），一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征descriptor。（7）将图像image内的所有block的HOG特征descriptor串联起来就可以得到该image（你要检测的目标）的HOG特征descriptor了。这个就是最终的可供分类使用的特征向量了。<br />  <strong><font color="red">Haar特征：</font></strong> Haar特征分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。Haar特征值反映了图像的灰度变化情况。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。<br />  <strong><font color="red">LBP特征：</font></strong> LBP（Local Binary Pattern，局部二值模式）是一种用来描述图像局部纹理特征的算子；它具有旋转不变性和灰度不变性等显著的优点。原始的LBP算子定义在一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>的窗口内，以窗口中心像素为阈值，与相邻的8个像素的灰度值比较，若周围的像素值大于中心像素值，则该位置被标记为1;，否则标记为0。如此可以得到一个8位二进制数（通常还要转换为10进制，即LBP码，共256种），将这个值作为窗口中心像素点的LBP值，以此来反应这个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>区域的纹理信息。</p><p><code>局部特征描述子——针对局部特征点：</code><br />  <strong><font color="red">BRIEF算法 ：</font></strong> BRIEF算法（Binary Robust IndependentElementary Features）的主要思想是：在特征点周围邻域内选取若干个像素点对，通过对这些点对的灰度值比较，将比较的结果组合成一个二进制串字符串用来描述特征点。最后，使用汉明距离来计算在特征描述子是否匹配。</p><h4 id="4-局部特征点检测和描述算法"><a class="markdownIt-Anchor" href="#4-局部特征点检测和描述算法"></a> 4. 局部特征点检测和描述算法</h4><p>  <strong><font color="red">SIFT算法：</font></strong> 尺度不变特征变换算法（Scale-invariant feature transform，SIFT）由Lowe在1999年所发表，2004年完善总结。利用原始图像与高斯核的卷积来建立尺度空间，在空间尺度中寻找极值点，并提取出其位置、尺度、旋转不变量。其中图像金字塔、计算图像梯度寻找主方向、梯度归一化，分别应对缩放不变、旋转不变、和光照不变，同时局部特征用于模式识别不需要考虑相对平移的影响，对视角变化、仿射变换、噪声也保持一定程度的稳定性。<br />  <strong><font color="red">SURF算法：</font></strong> SURF（Speeded Up Robust Features，加速稳健特征）发表于2006年的ECCV，是对SIFT算法加强版，同时加速的具有鲁棒性的特征。第二、标准的SURF算子比SIFT算子快好几倍，并且在多幅图片下具有更好的鲁棒性。SURF最大的特征在于采用了harr特征以及积分图像integral image的概念，这大大加快了程序的运行速度。<br />  <strong><font color="red">ORB算法：</font></strong> ORB算法的全称是Oriented FAST and Rotated BRIEF，算法分为使用FAST进行特征点检测，然后用BREIF进行特征点的特征描述，但是我们知道BRIEF并没有特征点方向的概念，所以ORB在BRIEF基础上引入了方向的计算方法，并在点对的挑选上使用贪婪搜索算法，挑出了一些区分性强的点对用来描述二进制串。<br />  <strong><font color="red">BRISK算法：</font></strong> BRISK算法主要利用FAST9-16进行特征点检测（为什么是主要？因为用到一次FAST5-8）。BRISK算法在特征点检测部分没有选用FAST特征点检测，而是选用了稳定性更强的AGAST算法。在特征描述子的构建中，BRISK算法通过利用简单的像素灰度值比较，进而得到一个级联的二进制比特串来描述每个特征点，这一点上原理与BRIEF是一致的。BRISK算法里采用了邻域采样模式，即以特征点为圆心，构建多个不同半径的离散化Bresenham同心圆，然后再每一个同心圆上获得具有相同间距的N个采样点。<br />  <strong><font color="red">FREAK算法：</font></strong> FREAK算法的全称是Fast Retina KeyPoint，即快速视网膜关键点。根据视网膜原理进行点对采样，中间密集一些，离中心越远越稀疏。并且由粗到精构建描述子，穷举贪婪搜索找相关性小的。42个感受野，一千对点的组合，找前512个即可。这512个分成4组，前128对相关性更小，可以代表粗的信息，后面越来越精。匹配的时候可以先看前16bytes，即代表精信息的部分，如果距离小于某个阈值，再继续，否则就不用往下看了。</p><h4 id="5-特征描述子的匹配match"><a class="markdownIt-Anchor" href="#5-特征描述子的匹配match"></a> 5. 特征描述子的匹配match</h4><p>  </p><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4><p>LBP描述子介绍：<a href="https://blog.csdn.net/hongbin_xu/article/details/79924961" target="_blank" rel="noopener">https://blog.csdn.net/hongbin_xu/article/details/79924961</a><br />SIFT算法简介1： <a href="https://www.cnblogs.com/cfantaisie/archive/2011/06/14/2080917.html" target="_blank" rel="noopener">https://www.cnblogs.com/cfantaisie/archive/2011/06/14/2080917.html</a><br />SIFT算法简介2：<a href="https://blog.csdn.net/wishchin/article/details/18319477" target="_blank" rel="noopener">https://blog.csdn.net/wishchin/article/details/18319477</a><br />SIFT算法详解 <a href="https://blog.csdn.net/memray/article/details/39234645" target="_blank" rel="noopener">https://blog.csdn.net/memray/article/details/39234645</a><br />SURF算法详解 <a href="https://www.cnblogs.com/gfgwxw/p/9415218.html" target="_blank" rel="noopener">https://www.cnblogs.com/gfgwxw/p/9415218.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  局部特征代表了图像的局部特性，一幅图像中旺旺能提取出若干个数量不等的局部特征，这些局部特征组合起来代表了整幅图像的特征分布。&lt;
      
    
    </summary>
    
    
    
      <category term="图像特征" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81/"/>
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读笔记——图像检索</title>
    <link href="http://holdfire.github.io/2019/11/06/papers-imageRetrieval01/"/>
    <id>http://holdfire.github.io/2019/11/06/papers-imageRetrieval01/</id>
    <published>2019-11-06T11:11:07.000Z</published>
    <updated>2019-11-06T14:35:05.648Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1-基于sift特征的图像检索的改进"><a class="markdownIt-Anchor" href="#1-基于sift特征的图像检索的改进"></a> 1. 基于SIFT特征的图像检索的改进</h5><p>  作者的highlights在于：（1）使用SIFT特征的关键点匹配两张图片时，将matched keypoints的数目M和距离d结合起来评估相似度得到评分<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">E_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>；（2）将queried images分成多张sub-image后，也分别进行检索评估相似度得到评分<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">E_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，然后将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">E_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">E_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>加权平均得到最终的相似度评分结果。<br />  论文链接：<a href="http://xueshu.baidu.com/usercenter/paper/show?paperid=2917562fcc9a75a6c187617f0e99b371&amp;site=xueshu_se" target="_blank" rel="noopener">Li B ,  Kong X ,  Wang Z , et al. SIFT-Based Image Retrieval Combining the Distance Measure of Global Image and Sub-Image[C]// Fifth International Conference on Intelligent Information Hiding &amp; Multimedia Signal Processing. IEEE Computer Society, 2009</a><br />`</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;1-基于sift特征的图像检索的改进&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-基于sift特征的图像检索的改进&quot;&gt;&lt;/a&gt; 1. 基于SIFT特征的图像检索的改进&lt;/h5&gt;
&lt;p&gt;  作者的highlights在于：（1）使用
      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://holdfire.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
      <category term="论文笔记" scheme="http://holdfire.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>图像检索——综述</title>
    <link href="http://holdfire.github.io/2019/11/06/cv-imageRetrieval-0/"/>
    <id>http://holdfire.github.io/2019/11/06/cv-imageRetrieval-0/</id>
    <published>2019-11-06T08:14:50.000Z</published>
    <updated>2019-11-06T12:26:19.890Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-简介"><a class="markdownIt-Anchor" href="#1-简介"></a> 1. 简介</h4><p>  图片库Lib中共有n张图片，现有待检索图片q，我们想在Lib中查找和图片q最相似的图片y。</p><h4 id="2-基于内容的图像检索cbir"><a class="markdownIt-Anchor" href="#2-基于内容的图像检索cbir"></a> 2. 基于内容的图像检索CBIR</h4><h5 id="21-基于局部特征"><a class="markdownIt-Anchor" href="#21-基于局部特征"></a> 2.1 基于局部特征</h5><p>  可选用的局部特征点包括角点和斑点两类，如：SIFT特征，SURF特征，ORB特征。流程如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">（1）对图片库Lib中图片，逐张提取局部特征点后生成描述子，将所有图片的描述子Desc保存在本地；</span><br><span class="line">（2）对待检索图片q提取局部特征并生成描述子desc_q；</span><br><span class="line">（3）将desc_q和图片库中图片的描述子进行match操作（判断是matched keypoints的规则见参考文献1），用matched kepoints的数目（设置一个阈值）及其距离来衡量其相似程度；</span><br><span class="line">（4）在图片库中所有图片进行查找（暴力查找或最近邻查找，如opencv提供的flann），根据相似度评分找到最优结果。</span><br></pre></td></tr></table></figure><h5 id="22-基于全局特征"><a class="markdownIt-Anchor" href="#22-基于全局特征"></a> 2.2 基于全局特征</h5><h5 id="23-基于cnn特征"><a class="markdownIt-Anchor" href="#23-基于cnn特征"></a> 2.3 基于CNN特征</h5><h4 id="3检索算法"><a class="markdownIt-Anchor" href="#3检索算法"></a> 3.检索算法</h4><h5 id="31-树形结构检索"><a class="markdownIt-Anchor" href="#31-树形结构检索"></a> 3.1 树形结构检索</h5><h5 id="32-基于哈希的方法"><a class="markdownIt-Anchor" href="#32-基于哈希的方法"></a> 3.2 基于哈希的方法</h5><h5 id="33-基于向量量化的方法"><a class="markdownIt-Anchor" href="#33-基于向量量化的方法"></a> 3.3 基于向量量化的方法</h5><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h4><ol><li>SIFT特征做图像检索论文：<a href="http://xueshu.baidu.com/usercenter/paper/show?paperid=2917562fcc9a75a6c187617f0e99b371&amp;site=xueshu_se" target="_blank" rel="noopener">SIFT-Based Image Retrieval Combining the Distance Measure of Global Image and Sub-Image</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-简介&quot;&gt;&lt;/a&gt; 1. 简介&lt;/h4&gt;
&lt;p&gt;  图片库Lib中共有n张图片，现有待检索图片q，我们想在Lib中查找和图片q最相似的图片y。&lt;/p&gt;
&lt;h4 id=&quot;2-基于内
      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://holdfire.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像检索" scheme="http://holdfire.github.io/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
</feed>
